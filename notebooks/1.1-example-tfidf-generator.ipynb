{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56920f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, MiniBatchNMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "tqdm.pandas()\n",
    "DB = 'StackSample.db'\n",
    "SEED = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd515f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query, db=DB):\n",
    "    with sql.connect(db) as conn:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_text_generator(rowids, db=DB):\n",
    "    with sql.connect(db) as conn:\n",
    "        for rowid in rowids:\n",
    "            query = f'select Body from df where rowid={rowid}'\n",
    "            text = conn.execute(query).fetchall()[0][0] # First element of the first tuple in the response\n",
    "            yield text\n",
    "            \n",
    "class Corpus():\n",
    "    def __init__(self, rowids, db):\n",
    "        self.rowids = rowids\n",
    "        self.db = db\n",
    "        \n",
    "    def __iter__(self):\n",
    "        with sql.connect(self.db) as conn:\n",
    "            for rowid in self.rowids:\n",
    "                query = f'select Body from df where rowid={rowid}'\n",
    "                text = conn.execute(query).fetchall()[0][0] # First element of the first tuple in the response\n",
    "                yield text\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.rowids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98487bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sql.connect(DB)\n",
    "rowids = [row[0] for row in conn.execute('select rowid from df where Split=0')]\n",
    "len(rowids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c521fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = get_text_generator(rowids)\n",
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ecd50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(rowids, DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79844519",
   "metadata": {},
   "source": [
    "Now let's train an NMF model. I'll also benchmark the time it takes to run this training. Remember, we are training from a dataset in memory. I am running an Intel i5-1135G7 X8 with 32GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f72e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    token_pattern=r'\\b[a-z]+\\b',\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "nmf = NMF(\n",
    "    n_components=100,\n",
    "    init='random',\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e06ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train vectorizer: 81.17s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_train_vect = vect.fit_transform(corpus)\n",
    "end = time.time()\n",
    "print(f'Time to train vectorizer: {end-start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "X_train_nmf = nmf.fit_transform(X_train_vect)\n",
    "end = time.time()\n",
    "print(f'Time to train NMF w/ {nmf.n_components} components: {end-start:02f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(nmf, 'nmf_100.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12ee31",
   "metadata": {},
   "source": [
    "Maybe it would be best to cycle through some different topic numbers and compare NMF to MiniBatchNMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b53b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_topics in [10, 20, 50, 100, 200]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c53c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn]",
   "language": "python",
   "name": "conda-env-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
